{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "L4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#[01] Seq2Seq"
      ],
      "metadata": {
        "id": "04mAtucamkzD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##(1) Data loading & preprocessing"
      ],
      "metadata": {
        "id": "9RFKcpRV2sYq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re, os, unicodedata, urllib3, zipfile, shutil\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "from collections import Counter\n",
        "from tqdm import tqdm\n",
        "from torch.utils.data import DataLoader, TensorDataset"
      ],
      "metadata": {
        "id": "E35gYvQpiymg"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_samples = 33000"
      ],
      "metadata": {
        "id": "cMrZwAoNws1B"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!wget -c http://www.manythings.org/anki/fra-eng.zip && unzip -o fra-eng.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TAp48D_Uwwqg",
        "outputId": "507f7663-0ba4-48f8-aaea-ec902847e184"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-07-17 07:01:28--  http://www.manythings.org/anki/fra-eng.zip\n",
            "Resolving www.manythings.org (www.manythings.org)... 173.254.30.110\n",
            "Connecting to www.manythings.org (www.manythings.org)|173.254.30.110|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 7943074 (7.6M) [application/zip]\n",
            "Saving to: ‘fra-eng.zip’\n",
            "\n",
            "fra-eng.zip         100%[===================>]   7.57M  4.14MB/s    in 1.8s    \n",
            "\n",
            "2024-07-17 07:01:31 (4.14 MB/s) - ‘fra-eng.zip’ saved [7943074/7943074]\n",
            "\n",
            "Archive:  fra-eng.zip\n",
            "  inflating: _about.txt              \n",
            "  inflating: fra.txt                 \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def unicode_to_ascii(s):\n",
        "    return ''.join(c for c in unicodedata.normalize('NFD', s) if unicodedata.category(c) != 'Mn')"
      ],
      "metadata": {
        "id": "NkEa4Rk6wzym"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_sentence(sent):\n",
        "    # 프랑스어 악센트(accent) 삭제\n",
        "    sent = unicode_to_ascii(sent.lower())\n",
        "\n",
        "    # 단어와 구두점 사이 공백 생성\n",
        "    # Ex) \"he is a boy.\" => \"he is a boy .\"\n",
        "    sent = re.sub(r\"([?.!,¿])\", r\" \\1\", sent)\n",
        "\n",
        "    # (a-z, A-Z, \".\", \"?\", \"!\", \",\") 를 제외하고 전부 공백으로 변환\n",
        "    sent = re.sub(r\"[^a-zA-Z!.?,]+\", r\" \", sent)\n",
        "\n",
        "    # 다수 개의 공백을 하나의 공백으로 치환\n",
        "    sent = re.sub(r\"\\s+\", \" \", sent)\n",
        "    return sent"
      ],
      "metadata": {
        "id": "rFFF8JRVw_dJ"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* 교사 강요(Teacher Forcing) 훈련을 위해, 디코더의 입력 시퀀스와, 레이블에 해당하는 출력 시퀀스를 분리\n",
        "* 입력 시퀀스에는 시작을 의미하는 토큰을 추가\n",
        "* 출력 시퀀스에는 종료를 의미하는 토큰을 추가"
      ],
      "metadata": {
        "id": "e6uKQgNICaUi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def load_preprocessed_data():\n",
        "    encoder_input, decoder_input, decoder_target = [], [], []\n",
        "\n",
        "    with open('fra.txt', \"r\") as lines:\n",
        "        for i, line in enumerate(lines):\n",
        "            # source 데이터와 target 데이터 분리\n",
        "            src_line, tar_line, _ = line.strip().split('\\t')\n",
        "\n",
        "            # source 데이터 전처리\n",
        "            src_line = [w for w in preprocess_sentence(src_line).split()]\n",
        "\n",
        "            # target 데이터 전처리\n",
        "            tar_line = preprocess_sentence(tar_line)\n",
        "            tar_line_in = [w for w in (\"<sos> \" + tar_line).split()]\n",
        "            tar_line_out = [w for w in (tar_line + \" <eos>\").split()]\n",
        "\n",
        "            encoder_input.append(src_line)\n",
        "            decoder_input.append(tar_line_in)\n",
        "            decoder_target.append(tar_line_out)\n",
        "\n",
        "            if i == num_samples - 1:\n",
        "                break\n",
        "\n",
        "    return encoder_input, decoder_input, decoder_target"
      ],
      "metadata": {
        "id": "FBlv7Doextgy"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 전처리 테스트\n",
        "en_sent = u\"Have you had dinner?\"\n",
        "fr_sent = u\"Avez-vous déjà diné?\"\n",
        "\n",
        "print('전처리 전 영어 문장 :', en_sent)\n",
        "print('전처리 후 영어 문장 :', preprocess_sentence(en_sent))\n",
        "print('전처리 전 프랑스어 문장 :', fr_sent)\n",
        "print('전처리 후 프랑스어 문장 :', preprocess_sentence(fr_sent))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LVJ9lMRRyctX",
        "outputId": "13e2d768-914b-4c7e-9ad3-892a88999a90"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "전처리 전 영어 문장 : Have you had dinner?\n",
            "전처리 후 영어 문장 : have you had dinner ?\n",
            "전처리 전 프랑스어 문장 : Avez-vous déjà diné?\n",
            "전처리 후 프랑스어 문장 : avez vous deja dine ?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sents_en_in, sents_fra_in, sents_fra_out = load_preprocessed_data()"
      ],
      "metadata": {
        "id": "FPEsSz3PyrjQ"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('인코더 입력 :', sents_en_in[:5])\n",
        "print('디코더 입력 :', sents_fra_in[:5])\n",
        "print('디코더 레이블 :', sents_fra_out[:5])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OLNcQagWyzuX",
        "outputId": "ca7c605e-f1d3-4915-b092-4bdef6edffd8"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "인코더 입력 : [['go', '.'], ['go', '.'], ['go', '.'], ['go', '.'], ['hi', '.']]\n",
            "디코더 입력 : [['<sos>', 'va', '!'], ['<sos>', 'marche', '.'], ['<sos>', 'en', 'route', '!'], ['<sos>', 'bouge', '!'], ['<sos>', 'salut', '!']]\n",
            "디코더 레이블 : [['va', '!', '<eos>'], ['marche', '.', '<eos>'], ['en', 'route', '!', '<eos>'], ['bouge', '!', '<eos>'], ['salut', '!', '<eos>']]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* 단어집합(Vocabulary): 단어로부터 정수를 얻는 딕셔너리\n",
        "* 패딩 토큰 <PAD> : 0번 & OOV 토큰 <UNK> : 1번"
      ],
      "metadata": {
        "id": "-xDkndNXC9FN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def build_vocab(sents):\n",
        "    word_list = []\n",
        "\n",
        "    for sent in sents:\n",
        "        for word in sent:\n",
        "            word_list.append(word)\n",
        "\n",
        "    # 각 단어별 등장 빈도를 계산하여 등장 빈도가 높은 순서로 정렬\n",
        "    word_counts = Counter(word_list)\n",
        "    vocab = sorted(word_counts, key=word_counts.get, reverse=True)\n",
        "\n",
        "    word_to_index = {}\n",
        "    word_to_index['<PAD>'] = 0\n",
        "    word_to_index['<UNK>'] = 1\n",
        "\n",
        "    # 등장 빈도가 높은 단어일수록 낮은 정수를 부여\n",
        "    for index, word in enumerate(vocab):\n",
        "        word_to_index[word] = index + 2\n",
        "\n",
        "    return word_to_index"
      ],
      "metadata": {
        "id": "h8IWxfOUzG2A"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "src_vocab = build_vocab(sents_en_in)\n",
        "tar_vocab = build_vocab(sents_fra_in + sents_fra_out)\n",
        "\n",
        "src_vocab_size = len(src_vocab)\n",
        "tar_vocab_size = len(tar_vocab)\n",
        "\n",
        "print('영어 단어 집합의 크기 : {:d}, 프랑스어 단어 집합의 크기 : {:d}'.format(src_vocab_size, tar_vocab_size))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V3mVIoK4z11w",
        "outputId": "fd74c79b-6b8c-412f-fdbd-57d9d653b1d1"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "영어 단어 집합의 크기 : 4487, 프랑스어 단어 집합의 크기 : 7880\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "index_to_src = {v : k for k, v in src_vocab.items()}\n",
        "index_to_tar = {v : k for k, v in tar_vocab.items()}\n",
        "\n",
        "def texts_to_sequences(sents, word_to_index):\n",
        "    encoded_X_data = []\n",
        "    for sent in tqdm(sents):\n",
        "        index_sequence = []\n",
        "        for word in sent:\n",
        "            try:\n",
        "                index_sequence.append(word_to_index[word])\n",
        "            except KeyError:\n",
        "                index_sequence.append(word_to_index['<UNK>'])\n",
        "        encoded_X_data.append(index_sequence)\n",
        "    return encoded_X_data"
      ],
      "metadata": {
        "id": "BXScQVj40JGn"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "encoder_input = texts_to_sequences(sents_en_in, src_vocab)\n",
        "decoder_input = texts_to_sequences(sents_fra_in, tar_vocab)\n",
        "decoder_target = texts_to_sequences(sents_fra_out, tar_vocab)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DcLZ9XM80oaB",
        "outputId": "1cecd27c-0263-4247-fd78-ba4a7ea27287"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 33000/33000 [00:00<00:00, 191067.85it/s]\n",
            "100%|██████████| 33000/33000 [00:00<00:00, 685856.59it/s]\n",
            "100%|██████████| 33000/33000 [00:00<00:00, 721538.62it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i, (item1, item2) in zip(range(5), zip(sents_en_in, encoder_input)):\n",
        "    print(f\"Index: {i}, 정수 인코딩 전: {item1}, 정수 인코딩 후: {item2}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lLXjHowq0zC_",
        "outputId": "27a404ec-c890-41b4-90bc-e0bce09e567f"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index: 0, 정수 인코딩 전: ['go', '.'], 정수 인코딩 후: [27, 2]\n",
            "Index: 1, 정수 인코딩 전: ['go', '.'], 정수 인코딩 후: [27, 2]\n",
            "Index: 2, 정수 인코딩 전: ['go', '.'], 정수 인코딩 후: [27, 2]\n",
            "Index: 3, 정수 인코딩 전: ['go', '.'], 정수 인코딩 후: [27, 2]\n",
            "Index: 4, 정수 인코딩 전: ['hi', '.'], 정수 인코딩 후: [737, 2]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def pad_sequences(sentences, max_len=None):\n",
        "    # 최대 길이 값이 주어지지 않을 경우 데이터 내 최대 길이로 패딩\n",
        "    if max_len is None:\n",
        "        max_len = max([len(sentence) for sentence in sentences])\n",
        "\n",
        "    features = np.zeros((len(sentences), max_len), dtype=int)\n",
        "    for index, sentence in enumerate(sentences):\n",
        "        if len(sentence) != 0:\n",
        "            features[index, :len(sentence)] = np.array(sentence)[:max_len]\n",
        "    return features"
      ],
      "metadata": {
        "id": "3V63et9B084P"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "encoder_input = pad_sequences(encoder_input)\n",
        "decoder_input = pad_sequences(decoder_input)\n",
        "decoder_target = pad_sequences(decoder_target)"
      ],
      "metadata": {
        "id": "Of3dvdp21ZS4"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('인코더 입력의 크기(shape) :', encoder_input.shape)\n",
        "print('디코더 입력의 크기(shape) :', decoder_input.shape)\n",
        "print('디코더 레이블의 크기(shape) :', decoder_target.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-N-aVLCO1fMn",
        "outputId": "e4c77e36-d834-4d1b-82e1-388f0106df01"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "인코더 입력의 크기(shape) : (33000, 7)\n",
            "디코더 입력의 크기(shape) : (33000, 16)\n",
            "디코더 레이블의 크기(shape) : (33000, 16)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "indices = np.arange(encoder_input.shape[0])\n",
        "np.random.shuffle(indices)\n",
        "print('랜덤 시퀀스 :', indices)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "foWyBzLM1oU-",
        "outputId": "b7345ed7-435f-4bca-a700-0f13d50a2157"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "랜덤 시퀀스 : [  474  5410  4220 ... 20286 27464 10058]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "encoder_input = encoder_input[indices]\n",
        "decoder_input = decoder_input[indices]\n",
        "decoder_target = decoder_target[indices]"
      ],
      "metadata": {
        "id": "V4wN_4k51u8n"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print([index_to_src[word] for word in encoder_input[30997]])\n",
        "print([index_to_tar[word] for word in decoder_input[30997]])\n",
        "print([index_to_tar[word] for word in decoder_target[30997]])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0rnp_JNy10Z2",
        "outputId": "6b1dcc3b-6552-4617-bd6f-0214564ae259"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['i', 'play', 'rugby', '.', '<PAD>', '<PAD>', '<PAD>']\n",
            "['<sos>', 'je', 'joue', 'au', 'rugby', '.', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>']\n",
            "['je', 'joue', 'au', 'rugby', '.', '<eos>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "n_of_val = int(33000 * 0.1)\n",
        "print('검증 데이터의 갯수 :', n_of_val)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MiHSqpPd2AoQ",
        "outputId": "d886f22e-5426-445e-d68d-68b7f3277c13"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "검증 데이터의 갯수 : 3300\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "encoder_input_train = encoder_input[:-n_of_val]\n",
        "decoder_input_train = decoder_input[:-n_of_val]\n",
        "decoder_target_train = decoder_target[:-n_of_val]\n",
        "\n",
        "encoder_input_test = encoder_input[-n_of_val:]\n",
        "decoder_input_test = decoder_input[-n_of_val:]\n",
        "decoder_target_test = decoder_target[-n_of_val:]"
      ],
      "metadata": {
        "id": "CcykM88W2HRH"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('훈련 source 데이터의 크기 :', encoder_input_train.shape)\n",
        "print('훈련 target 데이터의 크기 :', decoder_input_train.shape)\n",
        "print('훈련 target 레이블의 크기 :', decoder_target_train.shape)\n",
        "print('테스트 source 데이터의 크기 :',encoder_input_test.shape)\n",
        "print('테스트 target 데이터의 크기 :',decoder_input_test.shape)\n",
        "print('테스트 target 레이블의 크기 :',decoder_target_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TJqabKVk2ZYy",
        "outputId": "f532ec5b-b205-461d-8741-ca70429fb0fd"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "훈련 source 데이터의 크기 : (29700, 7)\n",
            "훈련 target 데이터의 크기 : (29700, 16)\n",
            "훈련 target 레이블의 크기 : (29700, 16)\n",
            "테스트 source 데이터의 크기 : (3300, 7)\n",
            "테스트 target 데이터의 크기 : (3300, 16)\n",
            "테스트 target 레이블의 크기 : (3300, 16)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##(2) Model Training"
      ],
      "metadata": {
        "id": "zFVh1pY02xij"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Encoder: 입력 시퀀스를 받아 해당 시퀀스의 정보를 압축하여 contexxt vector로 변환.\n",
        "* Encoder는 Embedding layer와 LSTM layer로 구성. Embedding layer는 입력 시퀀스의 각 토큰을 고정 크기의 벡터로 변환 / LSTM layer는 시퀀스의 순서 정보를 고려하여 해당 시퀀스를 요약\n",
        "* Encoder의 forward 메서드는 입력 시퀀스를 받아 LSTM의 hidden state와 cell state를 반환\n"
      ],
      "metadata": {
        "id": "8Ai-Ki9EDVTN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Decoder: encoder에서 생성한 context vector(인코더의 마지막 은닉 상태)를 기반으로 출력 시퀀스 생성.\n",
        "* Decoder는 Embedding layer와 LSTM layer로 구성. Decoder의 LSTM은 encoder에서 전달 받은 hidden state와 cell state를 초기상태로 사용하여 출력 시퀀스를 생성.\n",
        "* 생성된 출력 시퀀스는 fully conntected layer를 통과하여 각 시점의 출력 토큰에 대한 확률 분포를 얻음\n",
        "* Decoder의 forward 메서드는 입력 시퀀스, hidden state, cell state를 받아 출력 시퀀스, 업데이트된 hidden state와 cell state를 반환"
      ],
      "metadata": {
        "id": "_Cgmgf6TEjGO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Seq2Seq 클래스는 Encoder와 Decoder를 결합하여 전체 모델 구성\n",
        "* Seq2Seq 모델의 forward 메서드는 입력 시퀀스(src)와 출력 시퀀스(trg)를 받아 Encoder에서 생성한 은닉 상태(hidden state)와 셀 상태(cell state)를 Decoder로 전달하고, Decoder에서 생성한 출력 시퀀스를 반환\n",
        "\n",
        "* Seq2Seq의 Decoder는 각 시점마다 다중 클래스 분류 문제를 풀고 있음. 매 시점마다 프랑스어 단어 집합의 크기(tar_vocab_size)의 선택지에서 단어를 1개 선택하여 이를 이번 시점에서 예측한 단어로 택함.\n",
        "* 다중 클래스 분류 문제이므로 모델 학습을 위해 CrossEntropyLoss 손실 함수 사용, Adam optimizer로 파라미터 최적화. CrossEntropyLoss의 ignore_index는 패딩 토큰의 인덱스를 무시하도록 설정"
      ],
      "metadata": {
        "id": "VIKcjwRAFLp5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "embedding_dim = 256\n",
        "hidden_units = 256\n",
        "\n",
        "class Encoder(nn.Module):\n",
        "    def __init__(self, src_vocab_size, embedding_dim, hidden_units):\n",
        "        super(Encoder, self).__init__()\n",
        "        self.embedding = nn.Embedding(src_vocab_size, embedding_dim, padding_idx=0)\n",
        "        self.lstm = nn.LSTM(embedding_dim, hidden_units, batch_first=True)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # x.shape == (batch_size, seq_len, embedding_dim)\n",
        "        x = self.embedding(x)\n",
        "        # hidden.shape == (1, batch_size, hidden_units), cell.shape == (1, batch_size, hidden_units)\n",
        "        _, (hidden, cell) = self.lstm(x)\n",
        "        # 인코더의 출력은 hidden state, cell state\n",
        "        return hidden, cell\n",
        "\n",
        "class Decoder(nn.Module):\n",
        "    def __init__(self, tar_vocab_size, embedding_dim, hidden_units):\n",
        "        super(Decoder, self).__init__()\n",
        "        self.embedding = nn.Embedding(tar_vocab_size, embedding_dim, padding_idx=0)\n",
        "        self.lstm = nn.LSTM(embedding_dim, hidden_units, batch_first=True)\n",
        "        self.fc = nn.Linear(hidden_units, tar_vocab_size)\n",
        "\n",
        "    def forward(self, x, hidden, cell):\n",
        "        # x.shape == (batch_size, seq_len, embedding_dim)\n",
        "        x = self.embedding(x)\n",
        "\n",
        "        # 디코더의 LSTM으로 인코더의 hidden state, cell state 전달\n",
        "        # output.shape == (batch_size, seq_len, hidden_units)\n",
        "        # hidden.shape == (1, batch_size, hidden_units)\n",
        "        # cell.shape == (1, batch_size, hidden_units)\n",
        "        output, (hidden, cell) = self.lstm(x, (hidden, cell))\n",
        "\n",
        "        # output.shape == (batch_size, seq_len, tar_vocab_size)\n",
        "        output = self.fc(output)\n",
        "\n",
        "        # 디코더의 출력은 예측값, hidden state, cell state\n",
        "        return output, hidden, cell\n",
        "\n",
        "class Seq2Seq(nn.Module):\n",
        "    def __init__(self, encoder, decoder):\n",
        "        super(Seq2Seq, self).__init__()\n",
        "        self.encoder = encoder\n",
        "        self.decoder = decoder\n",
        "\n",
        "    def forward(self, src, trg):\n",
        "        hidden, cell = self.encoder(src)\n",
        "\n",
        "        # 훈련 중에는 디코더의 출력 중 오직 output만 사용한다.\n",
        "        output, _, _ = self.decoder(trg, hidden, cell)\n",
        "        return output\n",
        "\n",
        "encoder = Encoder(src_vocab_size, embedding_dim, hidden_units)\n",
        "decoder = Decoder(tar_vocab_size, embedding_dim, hidden_units)\n",
        "model = Seq2Seq(encoder, decoder)\n",
        "\n",
        "loss_function = nn.CrossEntropyLoss(ignore_index=0)\n",
        "optimizer = optim.Adam(model.parameters())"
      ],
      "metadata": {
        "id": "CBJpAnhQ2oxq"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wYIFHANR4rtX",
        "outputId": "fbdbebdd-36ea-468e-db43-8d834dc7a55b"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Seq2Seq(\n",
            "  (encoder): Encoder(\n",
            "    (embedding): Embedding(4487, 256, padding_idx=0)\n",
            "    (lstm): LSTM(256, 256, batch_first=True)\n",
            "  )\n",
            "  (decoder): Decoder(\n",
            "    (embedding): Embedding(7880, 256, padding_idx=0)\n",
            "    (lstm): LSTM(256, 256, batch_first=True)\n",
            "    (fc): Linear(in_features=256, out_features=7880, bias=True)\n",
            "  )\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluation(model, dataloader, loss_function, device):\n",
        "    model.eval()\n",
        "    total_loss = 0.0\n",
        "    total_correct = 0\n",
        "    total_count = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for encoder_inputs, decoder_inputs, decoder_targets in dataloader:\n",
        "            encoder_inputs = encoder_inputs.to(device)\n",
        "            decoder_inputs = decoder_inputs.to(device)\n",
        "            decoder_targets = decoder_targets.to(device)\n",
        "\n",
        "            # Forward propagation\n",
        "            # outputs.shape == (batch_size, seq_len, tar_vocab_size)\n",
        "            outputs = model(encoder_inputs, decoder_inputs)\n",
        "\n",
        "            # Calculate loss\n",
        "            # outputs.view(-1, outputs.size(-1))의 shape : (batch_size * seq_len, tar_vocab_size)\n",
        "            # decoder_targets.view(-1) shape : (batch_size * seq_len)\n",
        "            loss = loss_function(outputs.view(-1, outputs.size(-1)), decoder_targets.view(-1))\n",
        "            total_loss += loss.item()\n",
        "\n",
        "            # Accuracy (without padding token)\n",
        "            mask = decoder_targets != 0\n",
        "            total_correct += ((outputs.argmax(dim=-1) == decoder_targets) * mask).sum().item()\n",
        "            total_count += mask.sum().item()\n",
        "\n",
        "    return total_loss / len(dataloader), total_correct / total_count"
      ],
      "metadata": {
        "id": "lfYPtLV74tWO"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "encoder_input_train_tensor = torch.tensor(encoder_input_train, dtype=torch.long)\n",
        "decoder_input_train_tensor = torch.tensor(decoder_input_train, dtype=torch.long)\n",
        "decoder_target_train_tensor = torch.tensor(decoder_target_train, dtype=torch.long)\n",
        "\n",
        "encoder_input_test_tensor = torch.tensor(encoder_input_test, dtype=torch.long)\n",
        "decoder_input_test_tensor = torch.tensor(decoder_input_test, dtype=torch.long)\n",
        "decoder_target_test_tensor = torch.tensor(decoder_target_test, dtype=torch.long)\n",
        "\n",
        "# Dataset & DataLoader\n",
        "batch_size = 128\n",
        "\n",
        "train_dataset = TensorDataset(encoder_input_train_tensor, decoder_input_train_tensor, decoder_target_train_tensor)\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "valid_dataset = TensorDataset(encoder_input_test_tensor, decoder_input_test_tensor, decoder_target_test_tensor)\n",
        "valid_dataloader = DataLoader(valid_dataset, batch_size=batch_size, shuffle=False)"
      ],
      "metadata": {
        "id": "77Bhi0JL5pt6"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = 30\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "model.to(device)"
      ],
      "metadata": {
        "id": "6yCTo07M58wo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "best_val_loss = float('inf')\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    # Training\n",
        "    model.train()\n",
        "\n",
        "    for encoder_inputs, decoder_inputs, decoder_targets in train_dataloader:\n",
        "        encoder_inputs = encoder_inputs.to(device)\n",
        "        decoder_inputs = decoder_inputs.to(device)\n",
        "        decoder_targets = decoder_targets.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Forward pass\n",
        "        # outputs.shape == (batch_size, seq_len, tar_vocab_size)\n",
        "        outputs = model(encoder_inputs, decoder_inputs)\n",
        "\n",
        "        # Loss & Backpropagation\n",
        "        # outputs.view(-1, outputs.size(-1)) shape : (batch_size * seq_len, tar_vocab_size)\n",
        "        # decoder_targets.view(-1) shape : (batch_size * seq_len)\n",
        "        loss = loss_function(outputs.view(-1, outputs.size(-1)), decoder_targets.view(-1))\n",
        "        loss.backward()\n",
        "\n",
        "        # weight update\n",
        "        optimizer.step()\n",
        "\n",
        "    train_loss, train_acc = evaluation(model, train_dataloader, loss_function, device)\n",
        "    valid_loss, valid_acc = evaluation(model, valid_dataloader, loss_function, device)\n",
        "\n",
        "    print(f'Epoch: {epoch+1}/{num_epochs} | Train Loss: {train_loss:.4f} | Train Acc: {train_acc:.4f} | Valid Loss: {valid_loss:.4f} | Valid Acc: {valid_acc:.4f}')\n",
        "\n",
        "    # Save checkpoint\n",
        "    if valid_loss < best_val_loss:\n",
        "        print(f'Validation loss improved from {best_val_loss:.4f} to {valid_loss:.4f}. Saving checkpoint....')\n",
        "\n",
        "        best_val_loss = valid_loss\n",
        "        torch.save(model.state_dict(), 'best_model_checkpoint.pth')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nX4Iprv06Cup",
        "outputId": "e84c6c02-dc3a-470b-fa19-a34fe78ca506"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1/30 | Train Loss: 2.2758 | Train Acc: 0.6016 | Valid Loss: 2.5136 | Valid Acc: 0.5919\n",
            "Validation loss improved from inf to 2.5136. Saving checkpoint....\n",
            "Epoch: 2/30 | Train Loss: 1.8709 | Train Acc: 0.6437 | Valid Loss: 2.2296 | Valid Acc: 0.6207\n",
            "Validation loss improved from 2.5136 to 2.2296. Saving checkpoint....\n",
            "Epoch: 3/30 | Train Loss: 1.5645 | Train Acc: 0.6820 | Valid Loss: 2.0326 | Valid Acc: 0.6430\n",
            "Validation loss improved from 2.2296 to 2.0326. Saving checkpoint....\n",
            "Epoch: 4/30 | Train Loss: 1.3264 | Train Acc: 0.7123 | Valid Loss: 1.9004 | Valid Acc: 0.6602\n",
            "Validation loss improved from 2.0326 to 1.9004. Saving checkpoint....\n",
            "Epoch: 5/30 | Train Loss: 1.1007 | Train Acc: 0.7563 | Valid Loss: 1.7782 | Valid Acc: 0.6762\n",
            "Validation loss improved from 1.9004 to 1.7782. Saving checkpoint....\n",
            "Epoch: 6/30 | Train Loss: 0.9178 | Train Acc: 0.7903 | Valid Loss: 1.6954 | Valid Acc: 0.6881\n",
            "Validation loss improved from 1.7782 to 1.6954. Saving checkpoint....\n",
            "Epoch: 7/30 | Train Loss: 0.7643 | Train Acc: 0.8224 | Valid Loss: 1.6253 | Valid Acc: 0.6978\n",
            "Validation loss improved from 1.6954 to 1.6253. Saving checkpoint....\n",
            "Epoch: 8/30 | Train Loss: 0.6394 | Train Acc: 0.8488 | Valid Loss: 1.5780 | Valid Acc: 0.7033\n",
            "Validation loss improved from 1.6253 to 1.5780. Saving checkpoint....\n",
            "Epoch: 9/30 | Train Loss: 0.5451 | Train Acc: 0.8670 | Valid Loss: 1.5482 | Valid Acc: 0.7119\n",
            "Validation loss improved from 1.5780 to 1.5482. Saving checkpoint....\n",
            "Epoch: 10/30 | Train Loss: 0.4590 | Train Acc: 0.8879 | Valid Loss: 1.5193 | Valid Acc: 0.7163\n",
            "Validation loss improved from 1.5482 to 1.5193. Saving checkpoint....\n",
            "Epoch: 11/30 | Train Loss: 0.3970 | Train Acc: 0.8978 | Valid Loss: 1.5110 | Valid Acc: 0.7172\n",
            "Validation loss improved from 1.5193 to 1.5110. Saving checkpoint....\n",
            "Epoch: 12/30 | Train Loss: 0.3473 | Train Acc: 0.9067 | Valid Loss: 1.5063 | Valid Acc: 0.7202\n",
            "Validation loss improved from 1.5110 to 1.5063. Saving checkpoint....\n",
            "Epoch: 13/30 | Train Loss: 0.3067 | Train Acc: 0.9123 | Valid Loss: 1.5072 | Valid Acc: 0.7208\n",
            "Epoch: 14/30 | Train Loss: 0.2768 | Train Acc: 0.9175 | Valid Loss: 1.5175 | Valid Acc: 0.7229\n",
            "Epoch: 15/30 | Train Loss: 0.2517 | Train Acc: 0.9215 | Valid Loss: 1.5291 | Valid Acc: 0.7231\n",
            "Epoch: 16/30 | Train Loss: 0.2313 | Train Acc: 0.9244 | Valid Loss: 1.5311 | Valid Acc: 0.7222\n",
            "Epoch: 17/30 | Train Loss: 0.2190 | Train Acc: 0.9262 | Valid Loss: 1.5555 | Valid Acc: 0.7221\n",
            "Epoch: 18/30 | Train Loss: 0.2049 | Train Acc: 0.9283 | Valid Loss: 1.5534 | Valid Acc: 0.7228\n",
            "Epoch: 19/30 | Train Loss: 0.1972 | Train Acc: 0.9291 | Valid Loss: 1.5633 | Valid Acc: 0.7234\n",
            "Epoch: 20/30 | Train Loss: 0.1886 | Train Acc: 0.9298 | Valid Loss: 1.5808 | Valid Acc: 0.7194\n",
            "Epoch: 21/30 | Train Loss: 0.1843 | Train Acc: 0.9303 | Valid Loss: 1.5931 | Valid Acc: 0.7238\n",
            "Epoch: 22/30 | Train Loss: 0.1788 | Train Acc: 0.9309 | Valid Loss: 1.6024 | Valid Acc: 0.7211\n",
            "Epoch: 23/30 | Train Loss: 0.1748 | Train Acc: 0.9314 | Valid Loss: 1.6155 | Valid Acc: 0.7222\n",
            "Epoch: 24/30 | Train Loss: 0.1725 | Train Acc: 0.9314 | Valid Loss: 1.6173 | Valid Acc: 0.7233\n",
            "Epoch: 25/30 | Train Loss: 0.1666 | Train Acc: 0.9320 | Valid Loss: 1.6345 | Valid Acc: 0.7237\n",
            "Epoch: 26/30 | Train Loss: 0.1640 | Train Acc: 0.9321 | Valid Loss: 1.6382 | Valid Acc: 0.7222\n",
            "Epoch: 27/30 | Train Loss: 0.1599 | Train Acc: 0.9322 | Valid Loss: 1.6584 | Valid Acc: 0.7218\n",
            "Epoch: 28/30 | Train Loss: 0.1578 | Train Acc: 0.9325 | Valid Loss: 1.6646 | Valid Acc: 0.7229\n",
            "Epoch: 29/30 | Train Loss: 0.1563 | Train Acc: 0.9326 | Valid Loss: 1.6719 | Valid Acc: 0.7209\n",
            "Epoch: 30/30 | Train Loss: 0.1533 | Train Acc: 0.9329 | Valid Loss: 1.6702 | Valid Acc: 0.7249\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Model loading\n",
        "model.load_state_dict(torch.load('best_model_checkpoint.pth'))\n",
        "model.to(device)\n",
        "\n",
        "val_loss, val_accuracy = evaluation(model, valid_dataloader, loss_function, device)\n",
        "\n",
        "print(f'Best model validation loss: {val_loss:.4f}')\n",
        "print(f'Best model validation accuracy: {val_accuracy:.4f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TV9Cmd8O7N5P",
        "outputId": "1eda7f7a-fee2-4a82-bbe9-d56c2537bfab"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best model validation loss: 1.5063\n",
            "Best model validation accuracy: 0.7202\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(tar_vocab['<sos>'])\n",
        "print(tar_vocab['<eos>'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1nd1V7DJ7nY_",
        "outputId": "c1a64152-3bd5-43ec-aee6-859e5958bd77"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3\n",
            "4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##(3) Seq2seq Machine Translation"
      ],
      "metadata": {
        "id": "qgjPtcF37rWd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* seq2seq는 훈련과정(교사 강요)와 테스트 과정에서의 동작 방식이 다름\n",
        "* 번역 단계\n",
        "* 1) 번역하고자 하는 입력 문장에 인코더로 입력되어 인코더의 마지막 시점의 은닉 상태와 셀 상태 얻음\n",
        "* 2) 인코더의 은닉 상태와 셀 상태, 그리고 토큰 \\<sos\\>를 디코더로 보냄\n",
        "* 3) 디코더가 토큰 \\<eos\\>가 나올 때까지 다음 단어 예측"
      ],
      "metadata": {
        "id": "gbKDjcFnGjG8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "index_to_src = {v : k for k, v in src_vocab.items()}\n",
        "index_to_tar = {v : k for k, v in tar_vocab.items()}\n",
        "\n",
        "# 원문의 정수 시퀀스를 텍스트 시퀀스로 변환\n",
        "def seq_to_src(input_seq):\n",
        "    sentence = ''\n",
        "    for encoded_word in input_seq:\n",
        "        if (encoded_word != 0):\n",
        "            sentence = sentence + index_to_src[encoded_word] + ' '\n",
        "    return sentence\n",
        "\n",
        "# 번역문의 정수 시퀀스를 텍스트 시퀀스로 변환\n",
        "def seq_to_tar(input_seq):\n",
        "    sentence = ''\n",
        "    for encoded_word in input_seq:\n",
        "        if (encoded_word != 0 and encoded_word != tar_vocab['<sos>'] and encoded_word != tar_vocab['<eos>']):\n",
        "            sentence = sentence + index_to_tar[encoded_word] + ' '\n",
        "    return sentence"
      ],
      "metadata": {
        "id": "ro-rJd1kwzwg"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(encoder_input_test[25])\n",
        "print(decoder_input_test[25])\n",
        "print(decoder_target_test[25])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bw_pRc9I8834",
        "outputId": "fc3f18ef-8855-4c3c-ebf5-f8156dfff07b"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[  3  26  14 486 117   2   0]\n",
            "[   3    5   20   65   12 7187    2    0    0    0    0    0    0    0\n",
            "    0    0]\n",
            "[   5   20   65   12 7187    2    4    0    0    0    0    0    0    0\n",
            "    0    0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def decode_sequence(input_seq, model, src_vocab_size, tar_vocab_size, max_output_len, int_to_src_token, int_to_tar_token):\n",
        "    encoder_inputs = torch.tensor(input_seq, dtype=torch.long).unsqueeze(0).to(device)\n",
        "\n",
        "    # 인코더의 초기 상태 설정\n",
        "    hidden, cell = model.encoder(encoder_inputs)\n",
        "\n",
        "    # 시작 토큰 <sos>을 디코더의 첫 입력으로 설정\n",
        "    # unsqueeze(0)는 배치 차원을 추가하기 위함.\n",
        "    decoder_input = torch.tensor([3], dtype=torch.long).unsqueeze(0).to(device)\n",
        "\n",
        "    decoded_tokens = []\n",
        "\n",
        "    # for문을 도는 것 == 디코더의 각 시점\n",
        "    for _ in range(max_output_len):\n",
        "        output, hidden, cell = model.decoder(decoder_input, hidden, cell)\n",
        "\n",
        "        # 소프트맥스 회귀를 수행. 예측 단어의 인덱스\n",
        "        output_token = output.argmax(dim=-1).item()\n",
        "\n",
        "        # 종료 토큰 <eos>\n",
        "        if output_token == 4:\n",
        "            break\n",
        "\n",
        "        # 각 시점의 단어(정수)는 decoded_tokens에 누적하였다가 최종 번역 시퀀스로 리턴합니다.\n",
        "        decoded_tokens.append(output_token)\n",
        "\n",
        "        # 현재 시점의 예측. 다음 시점의 입력으로 사용된다.\n",
        "        decoder_input = torch.tensor([output_token], dtype=torch.long).unsqueeze(0).to(device)\n",
        "\n",
        "    return ' '.join(int_to_tar_token[token] for token in decoded_tokens)"
      ],
      "metadata": {
        "id": "gqbLhaQM9Dwn"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for seq_index in [3, 50, 100, 300, 1001]:\n",
        "  input_seq = encoder_input_train[seq_index]\n",
        "  translated_text = decode_sequence(input_seq, model, src_vocab_size, tar_vocab_size, 20, index_to_src, index_to_tar)\n",
        "\n",
        "  print(\"입력문장 :\",seq_to_src(encoder_input_train[seq_index]))\n",
        "  print(\"정답문장 :\",seq_to_tar(decoder_input_train[seq_index]))\n",
        "  print(\"번역문장 :\",translated_text)\n",
        "  print(\"-\"*50)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MSm7_iHR-HWg",
        "outputId": "3f9d1067-e948-4e26-acb2-1f6eb3a13770"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "입력문장 : what do you say ? \n",
            "정답문장 : que dis tu ? \n",
            "번역문장 : que dis tu ?\n",
            "--------------------------------------------------\n",
            "입력문장 : i missed supper . \n",
            "정답문장 : j ai loupe le diner . \n",
            "번역문장 : j ai loupe le souper .\n",
            "--------------------------------------------------\n",
            "입력문장 : you re mistaken . \n",
            "정답문장 : vous faites erreur . \n",
            "번역문장 : vous faites erreur .\n",
            "--------------------------------------------------\n",
            "입력문장 : how do we stop it ? \n",
            "정답문장 : comment l arretons nous ? \n",
            "번역문장 : comment le stoppons nous ?\n",
            "--------------------------------------------------\n",
            "입력문장 : look around you . \n",
            "정답문장 : regardez autour de vous . \n",
            "번역문장 : regardez autour de vous .\n",
            "--------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for seq_index in [3, 50, 100, 300, 1001]:\n",
        "  input_seq = encoder_input_test[seq_index]\n",
        "  translated_text = decode_sequence(input_seq, model, src_vocab_size, tar_vocab_size, 20, index_to_src, index_to_tar)\n",
        "\n",
        "  print(\"입력문장 :\",seq_to_src(encoder_input_test[seq_index]))\n",
        "  print(\"정답문장 :\",seq_to_tar(decoder_input_test[seq_index]))\n",
        "  print(\"번역문장 :\",translated_text)\n",
        "  print(\"-\"*50)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gki_OTLX-hI3",
        "outputId": "d6ad828a-5475-44be-d824-2d1865863727"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "입력문장 : i used to be lazy . \n",
            "정답문장 : j etais paresseux avant . \n",
            "번역문장 : j ai voulu la fete .\n",
            "--------------------------------------------------\n",
            "입력문장 : be objective . \n",
            "정답문장 : sois objective . \n",
            "번역문장 : soyez objectifs .\n",
            "--------------------------------------------------\n",
            "입력문장 : it smells burnt . \n",
            "정답문장 : ca sent le brule . \n",
            "번역문장 : ca semble etrange .\n",
            "--------------------------------------------------\n",
            "입력문장 : they re trapped . \n",
            "정답문장 : ils sont coinces . \n",
            "번역문장 : elles sont pieges .\n",
            "--------------------------------------------------\n",
            "입력문장 : here s your key . \n",
            "정답문장 : voici votre cle . \n",
            "번역문장 : ton probleme .\n",
            "--------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#[02] Attention"
      ],
      "metadata": {
        "id": "6F0e2KSZ_9N3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##(1) Model Training"
      ],
      "metadata": {
        "id": "IakT3Du_Y_O8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "embedding_dim = 256\n",
        "hidden_units = 256"
      ],
      "metadata": {
        "id": "MPPfyslRwzuK"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Encoder class"
      ],
      "metadata": {
        "id": "lFujqE9iZ0sn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Encoder(nn.Module):\n",
        "    def __init__(self, src_vocab_size, embedding_dim, hidden_units):\n",
        "        super(Encoder, self).__init__()\n",
        "        self.embedding = nn.Embedding(src_vocab_size, embedding_dim, padding_idx=0)\n",
        "        self.lstm = nn.LSTM(embedding_dim, hidden_units, batch_first=True)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # x.shape == (batch_size, seq_len, embedding_dim)\n",
        "        x = self.embedding(x)\n",
        "        # hidden.shape == (1, batch_size, hidden_units), cell.shape == (1, batch_size, hidden_units)\n",
        "        outputs, (hidden, cell) = self.lstm(x)\n",
        "        return outputs, hidden, cell"
      ],
      "metadata": {
        "id": "4t1yMP_IZP63"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Decoder class"
      ],
      "metadata": {
        "id": "gv0zC6RnZ3SF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Decoder class는 앞선 Seq2Seq와 달라짐.\n",
        "* Attention mechanism:\n",
        "* 1) Decoder의 hidden state와 Encoder의 모든 시점의 hidden state 간의 내적(dot product를 통해서 Attention scores 산출\n",
        "* 2) attention score를 softmax에 통과시켜 attension weights 산출\n",
        "* 3) attention weights를, value에 해당하는 encoder의 모든 시점의 hidden state와 각각 곱한 후, 이를 모두 더한 weighted sum => context vector 산출\n",
        "* 4) 이 context vector를 embedding vector와 concatenate하여 입력으로 사용"
      ],
      "metadata": {
        "id": "5C4g1E6PZ4n-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Decoder(nn.Module):\n",
        "    def __init__(self, tar_vocab_size, embedding_dim, hidden_units):\n",
        "        super(Decoder, self).__init__()\n",
        "        self.embedding = nn.Embedding(tar_vocab_size, embedding_dim, padding_idx=0)\n",
        "        self.lstm = nn.LSTM(embedding_dim + hidden_units, hidden_units, batch_first=True)\n",
        "        self.fc = nn.Linear(hidden_units, tar_vocab_size)\n",
        "        self.softmax = nn.Softmax(dim=2)\n",
        "\n",
        "    def forward(self, x, encoder_outputs, hidden, cell):\n",
        "        x = self.embedding(x)\n",
        "\n",
        "        # Dot product attention\n",
        "        # attention_scores.shape: (batch_size, source_seq_len, 1)\n",
        "        attention_scores = torch.bmm(encoder_outputs, hidden.transpose(0, 1).transpose(1, 2))\n",
        "\n",
        "        # attetion_weights.shape: (batch_size, source_seq_len, 1)\n",
        "        attention_weights = self.softmax(attention_scores)\n",
        "\n",
        "        # context_vector.shape: (batch_size, 1, hidden_units)\n",
        "        context_vector = torch.bmm(attention_weights.transpose(1, 2), encoder_outputs)\n",
        "\n",
        "        # Repeat context_vector to match seq_len\n",
        "        # context_vector_repeated.shape: (batch_size, target_seq_len, hidden_units)\n",
        "        seq_len = x.shape[1]\n",
        "        context_vector_repeated = context_vector.repeat(1, seq_len, 1)\n",
        "\n",
        "        # Concatenate context vector and embedded input\n",
        "        # x.shape: (batch_size, target_seq_len, embedding_dim + hidden_units)\n",
        "        x = torch.cat((x, context_vector_repeated), dim=2)\n",
        "\n",
        "        # output.shape: (batch_size, target_seq_len, hidden_units)\n",
        "        # hidden.shape: (1, batch_size, hidden_units)\n",
        "        # cell.shape: (1, batch_size, hidden_units)\n",
        "        output, (hidden, cell) = self.lstm(x, (hidden, cell))\n",
        "\n",
        "        # output.shape: (batch_size, target_seq_len, tar_vocab_size)\n",
        "        output = self.fc(output)\n",
        "\n",
        "        return output, hidden, cell"
      ],
      "metadata": {
        "id": "sdcIUGTuZP4v"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Seq2Seq(nn.Module):\n",
        "    def __init__(self, encoder, decoder):\n",
        "        super(Seq2Seq, self).__init__()\n",
        "        self.encoder = encoder\n",
        "        self.decoder = decoder\n",
        "\n",
        "    def forward(self, src, trg):\n",
        "        encoder_outputs, hidden, cell = self.encoder(src)\n",
        "        output, _, _ = self.decoder(trg, encoder_outputs, hidden, cell)\n",
        "        return output\n",
        "\n",
        "encoder = Encoder(src_vocab_size, embedding_dim, hidden_units)\n",
        "decoder = Decoder(tar_vocab_size, embedding_dim, hidden_units)\n",
        "model = Seq2Seq(encoder, decoder)\n",
        "\n",
        "loss_function = nn.CrossEntropyLoss(ignore_index=0)\n",
        "optimizer = optim.Adam(model.parameters())"
      ],
      "metadata": {
        "id": "aq49oGrIZP2R"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluation(model, dataloader, loss_function, device):\n",
        "    model.eval()\n",
        "    total_loss = 0.0\n",
        "    total_correct = 0\n",
        "    total_count = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for encoder_inputs, decoder_inputs, decoder_targets in dataloader:\n",
        "            encoder_inputs = encoder_inputs.to(device)\n",
        "            decoder_inputs = decoder_inputs.to(device)\n",
        "            decoder_targets = decoder_targets.to(device)\n",
        "\n",
        "            # forward pass\n",
        "            # outputs.shape == (batch_size, seq_len, tar_vocab_size)\n",
        "            outputs = model(encoder_inputs, decoder_inputs)\n",
        "\n",
        "            # Calculate loss\n",
        "            # outputs.view(-1, outputs.size(-1)) shape: (batch_size * seq_len, tar_vocab_size)\n",
        "            # decoder_targets.view(-1) shape: (batch_size * seq_len)\n",
        "            loss = loss_function(outputs.view(-1, outputs.size(-1)), decoder_targets.view(-1))\n",
        "            total_loss += loss.item()\n",
        "\n",
        "            # Calculate accuracy (without padding tokens)\n",
        "            mask = decoder_targets != 0\n",
        "            total_correct += ((outputs.argmax(dim=-1) == decoder_targets) * mask).sum().item()\n",
        "            total_count += mask.sum().item()\n",
        "\n",
        "    return total_loss / len(dataloader), total_correct / total_count"
      ],
      "metadata": {
        "id": "o5hmj5DEZPyE"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "encoder_input_train_tensor = torch.tensor(encoder_input_train, dtype=torch.long)\n",
        "decoder_input_train_tensor = torch.tensor(decoder_input_train, dtype=torch.long)\n",
        "decoder_target_train_tensor = torch.tensor(decoder_target_train, dtype=torch.long)\n",
        "\n",
        "encoder_input_test_tensor = torch.tensor(encoder_input_test, dtype=torch.long)\n",
        "decoder_input_test_tensor = torch.tensor(decoder_input_test, dtype=torch.long)\n",
        "decoder_target_test_tensor = torch.tensor(decoder_target_test, dtype=torch.long)\n",
        "\n",
        "# 데이터셋 및 데이터로더 생성\n",
        "batch_size = 128\n",
        "\n",
        "train_dataset = TensorDataset(encoder_input_train_tensor, decoder_input_train_tensor, decoder_target_train_tensor)\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "valid_dataset = TensorDataset(encoder_input_test_tensor, decoder_input_test_tensor, decoder_target_test_tensor)\n",
        "valid_dataloader = DataLoader(valid_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "# 학습 설정\n",
        "num_epochs = 30\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6m0unnTVZPwP",
        "outputId": "2212a0da-4c1f-49a1-9b2e-061b5d5a3271"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Seq2Seq(\n",
              "  (encoder): Encoder(\n",
              "    (embedding): Embedding(4487, 256, padding_idx=0)\n",
              "    (lstm): LSTM(256, 256, batch_first=True)\n",
              "  )\n",
              "  (decoder): Decoder(\n",
              "    (embedding): Embedding(7880, 256, padding_idx=0)\n",
              "    (lstm): LSTM(512, 256, batch_first=True)\n",
              "    (fc): Linear(in_features=256, out_features=7880, bias=True)\n",
              "    (softmax): Softmax(dim=2)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "best_val_loss = float('inf')\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    # Training\n",
        "    model.train()\n",
        "\n",
        "    for encoder_inputs, decoder_inputs, decoder_targets in train_dataloader:\n",
        "        encoder_inputs = encoder_inputs.to(device)\n",
        "        decoder_inputs = decoder_inputs.to(device)\n",
        "        decoder_targets = decoder_targets.to(device)\n",
        "\n",
        "        # initialize gradient\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # forward pass\n",
        "        # outputs.shape == (batch_size, seq_len, tar_vocab_size)\n",
        "        outputs = model(encoder_inputs, decoder_inputs)\n",
        "\n",
        "        # calculate loss and backpropagation\n",
        "        # outputs.view(-1, outputs.size(-1)) shape == (batch_size * seq_len, tar_vocab_size)\n",
        "        # decoder_targets.view(-1) shape == (batch_size * seq_len)\n",
        "        loss = loss_function(outputs.view(-1, outputs.size(-1)), decoder_targets.view(-1))\n",
        "        loss.backward()\n",
        "\n",
        "        # update weights\n",
        "        optimizer.step()\n",
        "\n",
        "    train_loss, train_acc = evaluation(model, train_dataloader, loss_function, device)\n",
        "    valid_loss, valid_acc = evaluation(model, valid_dataloader, loss_function, device)\n",
        "\n",
        "    print(f'\\nEpoch: {epoch+1} / {num_epochs} || Train Loss: {train_loss:.4f} | Train Acc: {train_acc:.4f} || Valid Loss: {valid_loss:.4f} | Valid Acc: {valid_acc:.4f}')\n",
        "    print('-' * 99)\n",
        "    print()\n",
        "\n",
        "    # Saving checkpoint\n",
        "    if valid_loss < best_val_loss:\n",
        "        print(f'\\nValidation loss improved from {best_val_loss:.4f} to {valid_loss:.4f}. Saving checkpoint....')\n",
        "        best_val_loss = valid_loss\n",
        "        torch.save(model.state_dict(), 'best_model_checkpoint.pth')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2zhGkaeDZPuI",
        "outputId": "182c2b51-f5fc-48a5-f00e-1560008f011e"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch: 1 / 30 || Train Loss: 2.8614 | Train Acc: 0.5472 || Valid Loss: 2.9906 | Valid Acc: 0.5435\n",
            "---------------------------------------------------------------------------------------------------\n",
            "\n",
            "\n",
            "Validation loss improved from inf to 2.9906. Saving checkpoint....\n",
            "\n",
            "Epoch: 2 / 30 || Train Loss: 2.1380 | Train Acc: 0.6220 || Valid Loss: 2.3884 | Valid Acc: 0.6061\n",
            "---------------------------------------------------------------------------------------------------\n",
            "\n",
            "\n",
            "Validation loss improved from 2.9906 to 2.3884. Saving checkpoint....\n",
            "\n",
            "Epoch: 3 / 30 || Train Loss: 1.6690 | Train Acc: 0.6771 || Valid Loss: 2.0538 | Valid Acc: 0.6423\n",
            "---------------------------------------------------------------------------------------------------\n",
            "\n",
            "\n",
            "Validation loss improved from 2.3884 to 2.0538. Saving checkpoint....\n",
            "\n",
            "Epoch: 4 / 30 || Train Loss: 1.3263 | Train Acc: 0.7226 || Valid Loss: 1.8445 | Valid Acc: 0.6664\n",
            "---------------------------------------------------------------------------------------------------\n",
            "\n",
            "\n",
            "Validation loss improved from 2.0538 to 1.8445. Saving checkpoint....\n",
            "\n",
            "Epoch: 5 / 30 || Train Loss: 1.0449 | Train Acc: 0.7712 || Valid Loss: 1.6806 | Valid Acc: 0.6912\n",
            "---------------------------------------------------------------------------------------------------\n",
            "\n",
            "\n",
            "Validation loss improved from 1.8445 to 1.6806. Saving checkpoint....\n",
            "\n",
            "Epoch: 6 / 30 || Train Loss: 0.8277 | Train Acc: 0.8101 || Valid Loss: 1.5759 | Valid Acc: 0.7038\n",
            "---------------------------------------------------------------------------------------------------\n",
            "\n",
            "\n",
            "Validation loss improved from 1.6806 to 1.5759. Saving checkpoint....\n",
            "\n",
            "Epoch: 7 / 30 || Train Loss: 0.6566 | Train Acc: 0.8475 || Valid Loss: 1.4978 | Valid Acc: 0.7152\n",
            "---------------------------------------------------------------------------------------------------\n",
            "\n",
            "\n",
            "Validation loss improved from 1.5759 to 1.4978. Saving checkpoint....\n",
            "\n",
            "Epoch: 8 / 30 || Train Loss: 0.5303 | Train Acc: 0.8693 || Valid Loss: 1.4535 | Valid Acc: 0.7215\n",
            "---------------------------------------------------------------------------------------------------\n",
            "\n",
            "\n",
            "Validation loss improved from 1.4978 to 1.4535. Saving checkpoint....\n",
            "\n",
            "Epoch: 9 / 30 || Train Loss: 0.4336 | Train Acc: 0.8898 || Valid Loss: 1.4166 | Valid Acc: 0.7281\n",
            "---------------------------------------------------------------------------------------------------\n",
            "\n",
            "\n",
            "Validation loss improved from 1.4535 to 1.4166. Saving checkpoint....\n",
            "\n",
            "Epoch: 10 / 30 || Train Loss: 0.3654 | Train Acc: 0.9008 || Valid Loss: 1.4041 | Valid Acc: 0.7311\n",
            "---------------------------------------------------------------------------------------------------\n",
            "\n",
            "\n",
            "Validation loss improved from 1.4166 to 1.4041. Saving checkpoint....\n",
            "\n",
            "Epoch: 11 / 30 || Train Loss: 0.3182 | Train Acc: 0.9100 || Valid Loss: 1.4093 | Valid Acc: 0.7336\n",
            "---------------------------------------------------------------------------------------------------\n",
            "\n",
            "\n",
            "Epoch: 12 / 30 || Train Loss: 0.2831 | Train Acc: 0.9154 || Valid Loss: 1.4138 | Valid Acc: 0.7308\n",
            "---------------------------------------------------------------------------------------------------\n",
            "\n",
            "\n",
            "Epoch: 13 / 30 || Train Loss: 0.2576 | Train Acc: 0.9197 || Valid Loss: 1.4166 | Valid Acc: 0.7318\n",
            "---------------------------------------------------------------------------------------------------\n",
            "\n",
            "\n",
            "Epoch: 14 / 30 || Train Loss: 0.2340 | Train Acc: 0.9235 || Valid Loss: 1.4216 | Valid Acc: 0.7344\n",
            "---------------------------------------------------------------------------------------------------\n",
            "\n",
            "\n",
            "Epoch: 15 / 30 || Train Loss: 0.2169 | Train Acc: 0.9260 || Valid Loss: 1.4350 | Valid Acc: 0.7310\n",
            "---------------------------------------------------------------------------------------------------\n",
            "\n",
            "\n",
            "Epoch: 16 / 30 || Train Loss: 0.2070 | Train Acc: 0.9273 || Valid Loss: 1.4447 | Valid Acc: 0.7331\n",
            "---------------------------------------------------------------------------------------------------\n",
            "\n",
            "\n",
            "Epoch: 17 / 30 || Train Loss: 0.1962 | Train Acc: 0.9285 || Valid Loss: 1.4598 | Valid Acc: 0.7311\n",
            "---------------------------------------------------------------------------------------------------\n",
            "\n",
            "\n",
            "Epoch: 18 / 30 || Train Loss: 0.1896 | Train Acc: 0.9294 || Valid Loss: 1.4672 | Valid Acc: 0.7347\n",
            "---------------------------------------------------------------------------------------------------\n",
            "\n",
            "\n",
            "Epoch: 19 / 30 || Train Loss: 0.1852 | Train Acc: 0.9299 || Valid Loss: 1.4761 | Valid Acc: 0.7349\n",
            "---------------------------------------------------------------------------------------------------\n",
            "\n",
            "\n",
            "Epoch: 20 / 30 || Train Loss: 0.1779 | Train Acc: 0.9306 || Valid Loss: 1.4870 | Valid Acc: 0.7340\n",
            "---------------------------------------------------------------------------------------------------\n",
            "\n",
            "\n",
            "Epoch: 21 / 30 || Train Loss: 0.1752 | Train Acc: 0.9311 || Valid Loss: 1.4898 | Valid Acc: 0.7336\n",
            "---------------------------------------------------------------------------------------------------\n",
            "\n",
            "\n",
            "Epoch: 22 / 30 || Train Loss: 0.1727 | Train Acc: 0.9307 || Valid Loss: 1.5123 | Valid Acc: 0.7336\n",
            "---------------------------------------------------------------------------------------------------\n",
            "\n",
            "\n",
            "Epoch: 23 / 30 || Train Loss: 0.1692 | Train Acc: 0.9311 || Valid Loss: 1.5159 | Valid Acc: 0.7320\n",
            "---------------------------------------------------------------------------------------------------\n",
            "\n",
            "\n",
            "Epoch: 24 / 30 || Train Loss: 0.1649 | Train Acc: 0.9317 || Valid Loss: 1.5235 | Valid Acc: 0.7345\n",
            "---------------------------------------------------------------------------------------------------\n",
            "\n",
            "\n",
            "Epoch: 25 / 30 || Train Loss: 0.1635 | Train Acc: 0.9317 || Valid Loss: 1.5299 | Valid Acc: 0.7337\n",
            "---------------------------------------------------------------------------------------------------\n",
            "\n",
            "\n",
            "Epoch: 26 / 30 || Train Loss: 0.1611 | Train Acc: 0.9318 || Valid Loss: 1.5523 | Valid Acc: 0.7354\n",
            "---------------------------------------------------------------------------------------------------\n",
            "\n",
            "\n",
            "Epoch: 27 / 30 || Train Loss: 0.1584 | Train Acc: 0.9319 || Valid Loss: 1.5451 | Valid Acc: 0.7360\n",
            "---------------------------------------------------------------------------------------------------\n",
            "\n",
            "\n",
            "Epoch: 28 / 30 || Train Loss: 0.1577 | Train Acc: 0.9326 || Valid Loss: 1.5717 | Valid Acc: 0.7338\n",
            "---------------------------------------------------------------------------------------------------\n",
            "\n",
            "\n",
            "Epoch: 29 / 30 || Train Loss: 0.1560 | Train Acc: 0.9323 || Valid Loss: 1.5645 | Valid Acc: 0.7326\n",
            "---------------------------------------------------------------------------------------------------\n",
            "\n",
            "\n",
            "Epoch: 30 / 30 || Train Loss: 0.1541 | Train Acc: 0.9321 || Valid Loss: 1.5743 | Valid Acc: 0.7319\n",
            "---------------------------------------------------------------------------------------------------\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load model\n",
        "model.load_state_dict(torch.load('best_model_checkpoint.pth'))\n",
        "model.to(device)\n",
        "\n",
        "val_loss, val_accuracy = evaluation(model, valid_dataloader, loss_function, device)\n",
        "\n",
        "print(f'Best model validation loss: {val_loss:.4f}')\n",
        "print(f'Best model validation accuracy: {val_accuracy:.4f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bV7XuuXXZPrr",
        "outputId": "50a34a4f-bf39-4680-ef8c-47009655f95a"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best model validation loss: 1.4041\n",
            "Best model validation accuracy: 0.7311\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##(2) Attention Machine Translation"
      ],
      "metadata": {
        "id": "EijGn2YZgrRG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(tar_vocab['<sos>'])\n",
        "print(tar_vocab['<eos>'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dn2DacX1ZPpr",
        "outputId": "147893f0-b18e-449e-8534-c6f73b3d535f"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3\n",
            "4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "index_to_src = {v: k for k, v in src_vocab.items()}\n",
        "index_to_tar = {v: k for k, v in tar_vocab.items()}\n",
        "\n",
        "# 원문의 정수 시퀀스를 텍스트 시퀀스로 변환\n",
        "def seq_to_src(input_seq):\n",
        "    sentence = ''\n",
        "    for encoded_word in input_seq:\n",
        "        if (encoded_word != 0):\n",
        "            sentence = sentence + index_to_src[encoded_word] + ' '\n",
        "    return sentence\n",
        "\n",
        "# 번역문의 정수 시퀀스를 텍스트 시퀀스로 변환\n",
        "def seq_to_tar(input_seq):\n",
        "    sentence = ''\n",
        "    for encoded_word in input_seq:\n",
        "        if (encoded_word != 0 and encoded_word != tar_vocab['<sos>'] and encoded_word != tar_vocab['<eos>']):\n",
        "            sentence = sentence + index_to_tar[encoded_word] + ' '\n",
        "    return sentence"
      ],
      "metadata": {
        "id": "Pr1fnNW0wzrs"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(encoder_input_test[25])\n",
        "print(decoder_input_test[25])\n",
        "print(decoder_target_test[25])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PtyTU3gshisS",
        "outputId": "2e57080a-75d7-46ee-e980-f48f260c3f3d"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ 63   8  37 751   2   0   0]\n",
            "[  3  14  28  41   9  12  19 804   2   0   0   0   0   0   0   0]\n",
            "[ 14  28  41   9  12  19 804   2   4   0   0   0   0   0   0   0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def decode_sequence(input_seq, model, src_vocab_size, tar_vocab_size, max_output_len, int_to_src_token, int_to_tar_token):\n",
        "    encoder_inputs = torch.tensor(input_seq, dtype=torch.long).unsqueeze(0).to(device)\n",
        "\n",
        "    # 인코더 초기 상태 설정\n",
        "    encoder_outputs, hidden, cell = model.encoder(encoder_inputs)\n",
        "\n",
        "    # 시작 토큰 <sos>를 디코더의 첫 입력으로 설정\n",
        "    # unsqueeze(0): batch 차원 추가\n",
        "    decoder_input = torch.tensor([3], dtype=torch.long).unsqueeze(0).to(device)\n",
        "\n",
        "    decoded_tokens = []\n",
        "\n",
        "    # iterating every timestep\n",
        "    for _ in range(max_output_len):\n",
        "        output, hidden, cell = model.decoder(decoder_input, encoder_outputs, hidden, cell)\n",
        "\n",
        "        # 소프트맥스 회귀 수행. 예측 단어의 인덱스\n",
        "        output_token = output.argmax(dim=-1).item()\n",
        "\n",
        "        # 종료 토큰 <eos>\n",
        "        if output_token == 4:\n",
        "            break\n",
        "\n",
        "        # 각 시점의 단어(정수)는 decoded_tokens에 누적하였다가 최종 번역 시퀀스로 리턴\n",
        "        decoded_tokens.append(output_token)\n",
        "\n",
        "        # 현재 시점의 예측을 다음 시점의 입력으로 사용\n",
        "        decoder_input = torch.tensor([output_token], dtype=torch.long).unsqueeze(0).to(device)\n",
        "\n",
        "    return ' '.join(int_to_tar_token[token] for token in decoded_tokens)"
      ],
      "metadata": {
        "id": "4EuLcnU9hnKa"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for seq_index in [3, 50, 100, 300, 1001]:\n",
        "    input_seq = encoder_input_train[seq_index]\n",
        "    translated_text = decode_sequence(input_seq, model, src_vocab_size, tar_vocab_size, 20, index_to_src, index_to_tar)\n",
        "\n",
        "    print('입력 문장 :', seq_to_src(encoder_input_train[seq_index]))\n",
        "    print('정답 문장 :', seq_to_tar(decoder_input_train[seq_index]))\n",
        "    print('번역 문장 :', translated_text)\n",
        "    print('-' * 49)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nmdyc6sNiygM",
        "outputId": "b3c19468-566f-4c22-fbdc-101303f4bc4c"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "입력 문장 : what do you want ? \n",
            "정답 문장 : que veux tu ? \n",
            "번역 문장 : que voulez vous ?\n",
            "-------------------------------------------------\n",
            "입력 문장 : we re normal . \n",
            "정답 문장 : nous sommes normaux . \n",
            "번역 문장 : nous sommes normales .\n",
            "-------------------------------------------------\n",
            "입력 문장 : i talk to myself . \n",
            "정답 문장 : je parle tout seul . \n",
            "번역 문장 : je parle tout seul .\n",
            "-------------------------------------------------\n",
            "입력 문장 : they are arguing . \n",
            "정답 문장 : ils se disputent . \n",
            "번역 문장 : elles sont en train de se disputer .\n",
            "-------------------------------------------------\n",
            "입력 문장 : tom likes country . \n",
            "정답 문장 : tom aime la country . \n",
            "번역 문장 : tom aime la country .\n",
            "-------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for seq_index in [3, 50, 100, 300, 1001]:\n",
        "  input_seq = encoder_input_test[seq_index]\n",
        "  translated_text = decode_sequence(input_seq, model, src_vocab_size, tar_vocab_size, 20, index_to_src, index_to_tar)\n",
        "\n",
        "  print(\"입력문장 :\",seq_to_src(encoder_input_test[seq_index]))\n",
        "  print(\"정답문장 :\",seq_to_tar(decoder_input_test[seq_index]))\n",
        "  print(\"번역문장 :\",translated_text)\n",
        "  print(\"-\"*50)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jqUdphGdjNoj",
        "outputId": "ea93a17b-e8b3-4f4e-f77b-3521320505db"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "입력문장 : tom is making tea . \n",
            "정답문장 : tom fait du the . \n",
            "번역문장 : tom est en train de faire du the .\n",
            "--------------------------------------------------\n",
            "입력문장 : do it this way . \n",
            "정답문장 : fais le de cette maniere . \n",
            "번역문장 : faites le de ca !\n",
            "--------------------------------------------------\n",
            "입력문장 : what woke you up ? \n",
            "정답문장 : qu est ce qui vous a reveilles ? \n",
            "번역문장 : qu est ce qui vous a reveillee ?\n",
            "--------------------------------------------------\n",
            "입력문장 : check this out . \n",
            "정답문장 : regarde moi ca . \n",
            "번역문장 : verifie ca .\n",
            "--------------------------------------------------\n",
            "입력문장 : let it be . \n",
            "정답문장 : ainsi soit il . \n",
            "번역문장 : laisse tomber .\n",
            "--------------------------------------------------\n"
          ]
        }
      ]
    }
  ]
}